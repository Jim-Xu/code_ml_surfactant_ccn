{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = '/data/keeling/a/xx24/e/proj_ml/cesm_data'\n",
    "dataset = 'd651001'\n",
    "data_dir = os.path.join(fp, dataset)\n",
    "\n",
    "output_dir = os.path.join(data_dir, \"ensemble_with_bulk\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "densities = {\n",
    "    'so4': 1800,\n",
    "    'ncl': 2200,\n",
    "    'pom': 1000,\n",
    "    'bc': 1800,\n",
    "    'dst': 2600,\n",
    "    'soa': 1400,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 扫描文件 & 按 (ens_letter, time, variable) 分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(\n",
    "    r'b\\.e21\\.(?P<prefix>BHIST_CESM2_2010_01_ens)'\n",
    "    r'(?P<num>\\d+)(?P<letter>[a-z]?)\\.cam\\.h0'\n",
    "    r'\\.(?P<var>[^.]+)\\.(?P<time>[^.]+)\\.nc'\n",
    ")\n",
    "\n",
    "grouped = {}\n",
    "for path in glob(os.path.join(data_dir, \"b.e21.*.cam.h0.*.nc\")):\n",
    "    fname = os.path.basename(path)\n",
    "    m = pattern.match(fname)\n",
    "    if not m:\n",
    "        continue\n",
    "    letter = m.group('letter') or 'a'\n",
    "    time_part = m.group('time')\n",
    "    var = m.group('var')\n",
    "    key = (letter, time_part, var)\n",
    "    grouped.setdefault(key, []).append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 对每组进行 ensemble 平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_avg = {}\n",
    "for (letter, time_part, var), paths in grouped.items():\n",
    "    arrs = []\n",
    "    coords0 = None\n",
    "    for p in paths:\n",
    "        ds = xr.open_dataset(p)\n",
    "        if var in ds:\n",
    "            arrs.append(ds[var])\n",
    "            if coords0 is None:\n",
    "                coords0 = ds.coords\n",
    "        ds.close()\n",
    "    if not arrs:\n",
    "        continue\n",
    "    combined = xr.concat(arrs, dim=\"ens_member\")\n",
    "    avg_da = combined.mean(dim=\"ens_member\")\n",
    "    ensemble_avg[(letter, time_part, var)] = (avg_da, coords0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 将 RHO_CLUBB 从 ilev 降到 lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_avg = {}\n",
    "for (letter, time_part, var), (da, coords) in ensemble_avg.items():\n",
    "    if var == 'RHO_CLUBB':\n",
    "        ilev = da.coords['ilev'].values    \n",
    "        t    = da.coords['time'].values\n",
    "        lat  = da.coords['lat'].values\n",
    "        lon  = da.coords['lon'].values\n",
    "        data = da.data                     \n",
    "\n",
    "        data_mid = 0.5 * (data[:, :-1, :, :] + data[:, 1:, :, :])   \n",
    "        lev_mid  = 0.5 * (ilev[:-1] + ilev[1:])                     \n",
    "\n",
    "        da_mid = xr.DataArray(\n",
    "            data_mid,\n",
    "            dims=('time', 'lev', 'lat', 'lon'),\n",
    "            coords={'time': t, 'lev': lev_mid, 'lat': lat, 'lon': lon},\n",
    "            name='RHO_CLUBB'\n",
    "        )\n",
    "        new_avg[(letter, time_part, var)] = (da_mid, da_mid.coords)\n",
    "    else:\n",
    "        new_avg[(letter, time_part, var)] = (da, coords)\n",
    "\n",
    "ensemble_avg = new_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 计算 bulk diameter 及各 species mass_vol / number conc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = ['so4','ncl','pom','bc','dst','soa','num']\n",
    "bulk_results = {}\n",
    "\n",
    "for letter, time_part in set((k[0], k[1]) for k in ensemble_avg):\n",
    "    summed = {}\n",
    "    coords0 = None\n",
    "    for sp in species_list:\n",
    "        arrs = [ da for (l,t,var),(da,_) in ensemble_avg.items()\n",
    "                 if l==letter and t==time_part and var.startswith(sp+'_') ]\n",
    "        if arrs:\n",
    "            summed[sp] = sum(arrs)\n",
    "            coords0 = arrs[0].coords\n",
    "\n",
    "    da_rho, _ = ensemble_avg.get((letter, time_part, 'RHO_CLUBB'), (None,None))\n",
    "    if da_rho is None:\n",
    "        continue\n",
    "\n",
    "    mass_vol = {}\n",
    "    for sp, rho_sp in densities.items():\n",
    "        da_sp = summed.get(sp)\n",
    "        if da_sp is not None:\n",
    "            mass_vol[sp] = da_sp * da_rho\n",
    "\n",
    "    da_num = summed.get('num')\n",
    "    if da_num is None:\n",
    "        continue\n",
    "    N_tot = da_num * da_rho\n",
    "\n",
    "    M_tot = sum(mass_vol.values())                                \n",
    "    V_tot = sum(mass_vol[sp] / densities[sp] for sp in mass_vol)  \n",
    "    rho_mix = M_tot / V_tot\n",
    "    d_bulk  = ((6 * M_tot) / (np.pi * rho_mix * N_tot)) ** (1/3)\n",
    "\n",
    "    bulk_results[(letter, time_part)] = {\n",
    "        'coords': coords0,\n",
    "        'mass_vol': mass_vol,\n",
    "        'N_tot':   N_tot,\n",
    "        'bulk':    d_bulk\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 合并所有变量到一个 Dataset 并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (letter, time_part), res in bulk_results.items():\n",
    "    ds_out = xr.Dataset(coords=res['coords'])\n",
    "\n",
    "    for sp, mv in res['mass_vol'].items():\n",
    "        ds_out[sp] = mv\n",
    "\n",
    "    ds_out['tot_number_conc'] = res['N_tot']\n",
    "\n",
    "    ds_out['bulk_diameter'] = res['bulk']\n",
    "\n",
    "    for var in ['T', 'RELHUM', 'RHO_CLUBB', 'CCN3']:\n",
    "        entry = ensemble_avg.get((letter, time_part, var))\n",
    "        if entry:\n",
    "            ds_out[var] = entry[0]\n",
    "\n",
    "    fname = f\"b.e21.ens_{letter}.cam.h0.all_vars.{time_part}.nc\"\n",
    "    outpath = os.path.join(output_dir, fname)\n",
    "    ds_out.to_netcdf(outpath)\n",
    "    print(\"Saved:\", outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = [\n",
    "    '/data/keeling/a/xx24/e/proj_ml/cesm_data/d651001/ensemble_combined/b.e21.ens_a.cam.h0.all_vars.201001-201112.nc',\n",
    "    '/data/keeling/a/xx24/e/proj_ml/cesm_data/d651001/ensemble_combined/b.e21.ens_b.cam.h0.all_vars.201001-201112.nc',\n",
    "    '/data/keeling/a/xx24/e/proj_ml/cesm_data/d651001/ensemble_combined/b.e21.ens_c.cam.h0.all_vars.201001-201112.nc',\n",
    "    '/data/keeling/a/xx24/e/proj_ml/cesm_data/d651001/ensemble_combined/b.e21.ens_d.cam.h0.all_vars.201001-201112.nc',\n",
    "    '/data/keeling/a/xx24/e/proj_ml/cesm_data/d651001/ensemble_combined/b.e21.ens_e.cam.h0.all_vars.201001-201112.nc'\n",
    "]\n",
    "\n",
    "ens_members = [f.split('ens_')[1][0] for f in filepaths]\n",
    "\n",
    "datasets = []\n",
    "for member, file in zip(ens_members, filepaths):\n",
    "    ds = xr.open_dataset(file)\n",
    "    ds_expanded = ds.expand_dims(ensemble=[member])\n",
    "    datasets.append(ds_expanded)\n",
    "\n",
    "combined = xr.concat(datasets, dim='ensemble')\n",
    "\n",
    "mean_ds = combined.mean(dim='ensemble', keep_attrs=True)  # 保留属性\n",
    "\n",
    "mean_ds.to_netcdf('/data/keeling/a/xx24/e/proj_ml/cesm_data/d651001/ensemble_combined/ensemble_mean.nc')\n",
    "\n",
    "print(\"Saved as ensemble_mean.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
